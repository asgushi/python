from collections import Counter
import json, os, sqlite3

#verifica as palavras mais utilizadas com base no arquivo txt (o qual contém mensagens JSON)

tweets_data_path = 'C:\\Users\\agushi\\Desktop\\Python\\Tweets TD.txt'

tweets_file = open(tweets_data_path, "r")
tweets_data = []
textos_juntos = []

#gerando um array único (textos_juntos) contendo todas as palavras separadas
for line in tweets_file:
    try:
        tweet = json.loads(line)
        tweets_data.append(tweet)
        texto = tweet['text']
        separar_texto = texto.split(" ")
        for palavra in separar_texto:
            encodedpalavra = palavra#.encode("utf-8", errors='ignore')
            textos_juntos.append(encodedpalavra)
    except:
        continue

print(textos_juntos)
#textos_juntos.remove("la")

print(str(len(textos_juntos)) + " palavras a serem analisadas...")
print("")

#verificando quais as palavras mais usadas
moda_palavras = Counter(textos_juntos).most_common(100)

#printando o resultado
print("Lista das 20 palavras mais usadas:")
print("-----------------------------------")
for unu in range(20):
    print(str(unu+1) + "º - " + str(moda_palavras[unu]))
  
